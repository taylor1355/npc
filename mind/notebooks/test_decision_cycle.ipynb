{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NPC Decision Cycle Testing\n",
    "\n",
    "This notebook provides full observability into the NPC cognitive pipeline, showing all intermediate processing steps, token usage, and timing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import asyncio\n",
    "from typing import Any\n",
    "from dataclasses import dataclass\n",
    "import logging\n",
    "\n",
    "# Use the clean client instead of the one with LlamaIndex dependencies\n",
    "from mind.agent.agent import Agent, AgentLLMConfig\n",
    "from mind.apis.clean_llm_client import Model\n",
    "\n",
    "# Set up logging to see all intermediate steps\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Token Counter\n",
    "\n",
    "Simple token counting utility to measure usage at each step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "\n",
    "@dataclass\n",
    "class TokenUsage:\n",
    "    \"\"\"Track token usage for a single LLM call\"\"\"\n",
    "    step: str\n",
    "    input_tokens: int\n",
    "    output_tokens: int\n",
    "    total_tokens: int\n",
    "    duration_ms: int\n",
    "    \n",
    "class TokenTracker:\n",
    "    \"\"\"Track token usage across the pipeline\"\"\"\n",
    "    def __init__(self):\n",
    "        self.encoder = tiktoken.encoding_for_model(\"gpt-4\")  # Close enough for Claude\n",
    "        self.usage_history: list[TokenUsage] = []\n",
    "    \n",
    "    def count_tokens(self, text: str) -> int:\n",
    "        \"\"\"Count tokens in a string\"\"\"\n",
    "        return len(self.encoder.encode(text))\n",
    "    \n",
    "    def track_call(self, step: str, input_text: str, output_text: str, duration_ms: int):\n",
    "        \"\"\"Track a single LLM call\"\"\"\n",
    "        usage = TokenUsage(\n",
    "            step=step,\n",
    "            input_tokens=self.count_tokens(input_text),\n",
    "            output_tokens=self.count_tokens(output_text),\n",
    "            total_tokens=self.count_tokens(input_text) + self.count_tokens(output_text),\n",
    "            duration_ms=duration_ms\n",
    "        )\n",
    "        self.usage_history.append(usage)\n",
    "        return usage\n",
    "    \n",
    "    def summary(self) -> dict[str, Any]:\n",
    "        \"\"\"Get summary of all token usage\"\"\"\n",
    "        total_input = sum(u.input_tokens for u in self.usage_history)\n",
    "        total_output = sum(u.output_tokens for u in self.usage_history)\n",
    "        total_time = sum(u.duration_ms for u in self.usage_history)\n",
    "        \n",
    "        return {\n",
    "            \"total_input_tokens\": total_input,\n",
    "            \"total_output_tokens\": total_output,\n",
    "            \"total_tokens\": total_input + total_output,\n",
    "            \"total_duration_ms\": total_time,\n",
    "            \"steps\": [{\n",
    "                \"step\": u.step,\n",
    "                \"tokens\": u.total_tokens,\n",
    "                \"duration_ms\": u.duration_ms\n",
    "            } for u in self.usage_history]\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observable Agent Wrapper\n",
    "\n",
    "Wrap the Agent class to capture and display all intermediate processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ObservableAgent(Agent):\n",
    "    \"\"\"Agent wrapper that logs all intermediate steps for observation\"\"\"\n",
    "    \n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.tracker = TokenTracker()\n",
    "        self.intermediate_results = {}\n",
    "    \n",
    "    def _log_step(self, step_name: str, result: Any, input_text: str = \"\", duration_ms: int = 0):\n",
    "        \"\"\"Log and display intermediate step results\"\"\"\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"STEP: {step_name}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        if isinstance(result, dict):\n",
    "            print(json.dumps(result, indent=2))\n",
    "        elif isinstance(result, list):\n",
    "            for i, item in enumerate(result):\n",
    "                print(f\"  [{i}]: {item}\")\n",
    "        else:\n",
    "            print(result)\n",
    "        \n",
    "        # Track tokens if we have text\n",
    "        if input_text and result:\n",
    "            output_text = json.dumps(result) if isinstance(result, (dict, list)) else str(result)\n",
    "            usage = self.tracker.track_call(step_name, input_text, output_text, duration_ms)\n",
    "            print(f\"\\nTokens: {usage.total_tokens} (in: {usage.input_tokens}, out: {usage.output_tokens})\")\n",
    "            print(f\"Time: {usage.duration_ms}ms\")\n",
    "        \n",
    "        # Store for later analysis\n",
    "        self.intermediate_results[step_name] = result\n",
    "    \n",
    "    def update_working_memory(self) -> None:\n",
    "        \"\"\"Override to capture intermediate results\"\"\"\n",
    "        print(\"\\n\" + \"#\"*70)\n",
    "        print(\"# UPDATING WORKING MEMORY\")\n",
    "        print(\"#\"*70)\n",
    "        \n",
    "        # Current state\n",
    "        print(f\"\\nCurrent Working Memory:\\n{self.working_memory}\\n\")\n",
    "        print(f\"Current Observation:\\n{self.current_observation}\\n\")\n",
    "        \n",
    "        # Step 1: Generate queries\n",
    "        start_time = time.time()\n",
    "        query_response = self.query_generator.generate(\n",
    "            working_memory=self.working_memory,\n",
    "            observation=self.current_observation,\n",
    "        )\n",
    "        duration = int((time.time() - start_time) * 1000)\n",
    "        self._log_step(\"1. Memory Queries Generated\", query_response, \n",
    "                      f\"WM: {self.working_memory}\\nObs: {self.current_observation}\", duration)\n",
    "        \n",
    "        # Step 2: Retrieve memories\n",
    "        retrieved_memories = []\n",
    "        for query in query_response.get(\"queries\", []):\n",
    "            query_memories = self.long_term_memory.retrieve(query)\n",
    "            if query_memories:\n",
    "                retrieved_memories.append(f\"Query: '{query}' -> Memory: '{query_memories[0]}'\")\n",
    "        self._log_step(\"2. Memories Retrieved\", retrieved_memories)\n",
    "        \n",
    "        # Step 3: Generate memory report\n",
    "        start_time = time.time()\n",
    "        memory_report_response = self.memory_report_generator.generate(\n",
    "            working_memory=self.working_memory,\n",
    "            observation=self.current_observation,\n",
    "            retrieved_memories=[m.split(\" -> Memory: '\")[1].rstrip(\"'\") for m in retrieved_memories] if retrieved_memories else [],\n",
    "        )\n",
    "        duration = int((time.time() - start_time) * 1000)\n",
    "        self._log_step(\"3. Memory Report Generated\", memory_report_response,\n",
    "                      f\"WM: {self.working_memory}\\nMemories: {retrieved_memories}\", duration)\n",
    "        \n",
    "        # Step 4: Update working memory\n",
    "        start_time = time.time()\n",
    "        working_memory_response = self.working_memory_generator.generate(\n",
    "            working_memory=self.working_memory,\n",
    "            memory_report=memory_report_response[\"memory_report\"],\n",
    "        )\n",
    "        duration = int((time.time() - start_time) * 1000)\n",
    "        self._log_step(\"4. Working Memory Updated\", working_memory_response,\n",
    "                      f\"Report: {memory_report_response['memory_report']}\", duration)\n",
    "        \n",
    "        if working_memory_response[\"updated_working_memory\"]:\n",
    "            self.working_memory = working_memory_response[\"updated_working_memory\"]\n",
    "            print(f\"\\nNew Working Memory:\\n{self.working_memory}\")\n",
    "    \n",
    "    def update_long_term_memory(self) -> None:\n",
    "        \"\"\"Override to capture intermediate results\"\"\"\n",
    "        print(\"\\n\" + \"#\"*70)\n",
    "        print(\"# UPDATING LONG-TERM MEMORY\")\n",
    "        print(\"#\"*70)\n",
    "        \n",
    "        start_time = time.time()\n",
    "        memory_update_response = self.long_term_memory_generator.generate(\n",
    "            working_memory=self.working_memory,\n",
    "            observation=self.current_observation,\n",
    "        )\n",
    "        duration = int((time.time() - start_time) * 1000)\n",
    "        self._log_step(\"5. Long-term Memories Generated\", memory_update_response,\n",
    "                      f\"WM: {self.working_memory}\\nObs: {self.current_observation}\", duration)\n",
    "        \n",
    "        for memory in memory_update_response[\"memories\"]:\n",
    "            self.long_term_memory.add_memories([memory])\n",
    "            print(f\"  Added to LTM: {memory}\")\n",
    "    \n",
    "    def choose_action(self) -> int:\n",
    "        \"\"\"Override to capture intermediate results\"\"\"\n",
    "        print(\"\\n\" + \"#\"*70)\n",
    "        print(\"# CHOOSING ACTION\")\n",
    "        print(\"#\"*70)\n",
    "        \n",
    "        # Format available actions\n",
    "        actions_str = \"\\n\".join([\n",
    "            f\"- Action {idx}: {desc}\"\n",
    "            for idx, desc in self.current_actions.items()\n",
    "        ])\n",
    "        print(f\"\\nAvailable Actions:\\n{actions_str}\")\n",
    "        \n",
    "        # Get action decision\n",
    "        start_time = time.time()\n",
    "        next_action = self.action_decision_generator.generate(\n",
    "            working_memory=self.working_memory,\n",
    "            available_actions=actions_str,\n",
    "            personality_traits=\", \".join(self.personality_traits)\n",
    "        )\n",
    "        duration = int((time.time() - start_time) * 1000)\n",
    "        self._log_step(\"6. Action Decision Made\", next_action,\n",
    "                      f\"WM: {self.working_memory}\\nActions: {actions_str}\", duration)\n",
    "        \n",
    "        # Extract chosen action\n",
    "        try:\n",
    "            action_decision = json.loads(next_action[\"action_decision\"])\n",
    "            chosen_index = int(action_decision[\"action_index\"])\n",
    "            print(f\"\\nChosen Action: {chosen_index} - {self.current_actions[chosen_index]}\")\n",
    "            return chosen_index\n",
    "        except (KeyError, ValueError, json.JSONDecodeError) as e:\n",
    "            print(f\"\\nError parsing action: {e}\")\n",
    "            return list(self.current_actions.keys())[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Scenario Setup\n",
    "\n",
    "Create a realistic test scenario with preset agent state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure LLMs\n",
    "llm_config = AgentLLMConfig(\n",
    "    small_llm=Model.GEMINI_FLASH,\n",
    "    large_llm=Model.CLAUDE_SONNET,\n",
    ")\n",
    "\n",
    "# Initial agent state\n",
    "initial_working_memory = \"\"\"I am a blacksmith in the village. I've been working on a sword commission for the past two days. \n",
    "This morning I feel well-rested and ready to continue my work. My apprentice should arrive soon to help.\n",
    "I need to finish the blade today and start on the handle tomorrow.\"\"\"\n",
    "\n",
    "initial_memories = [\n",
    "    \"Yesterday I shaped the blade and got it to the right length\",\n",
    "    \"The customer wants a ceremonial sword with intricate engravings\",\n",
    "    \"My apprentice has been learning quickly and can now help with basic tasks\",\n",
    "    \"The forge needs more coal soon, running low on supplies\",\n",
    "    \"Last week I completed a set of horseshoes for the stable\",\n",
    "    \"The village festival is coming up in three days\",\n",
    "    \"I promised my wife I would come home early today\"\n",
    "]\n",
    "\n",
    "personality_traits = [\"hardworking\", \"perfectionist\", \"patient teacher\"]\n",
    "\n",
    "# Test observation and actions\n",
    "test_observation = \"\"\"You are in your workshop at the forge. The morning sun streams through the window. \n",
    "Your apprentice just arrived and greets you cheerfully. The half-finished sword blade lies on your workbench. \n",
    "The forge fire has died down overnight and needs to be restarted. You hear the village bell tower chime 8 o'clock.\"\"\"\n",
    "\n",
    "test_actions = {\n",
    "    0: \"Greet your apprentice and ask them to restart the forge fire\",\n",
    "    1: \"Immediately begin working on the sword blade yourself\", \n",
    "    2: \"Take a moment to inspect yesterday's work on the blade\",\n",
    "    3: \"Go to the storage room to check coal supplies\",\n",
    "    4: \"Start teaching your apprentice a new technique\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Decision Cycle\n",
    "\n",
    "Execute a single decision cycle with full observability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create observable agent\n",
    "agent = ObservableAgent(\n",
    "    llm_config=llm_config,\n",
    "    initial_working_memory=initial_working_memory,\n",
    "    initial_long_term_memories=initial_memories,\n",
    "    personality_traits=personality_traits\n",
    ")\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"STARTING DECISION CYCLE\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nInitial State:\")\n",
    "print(f\"  Working Memory: {len(initial_working_memory)} chars\")\n",
    "print(f\"  Long-term Memories: {len(initial_memories)} memories\")\n",
    "print(f\"  Personality: {personality_traits}\")\n",
    "print(f\"\\nObservation: {test_observation}\")\n",
    "print(f\"\\nAvailable Actions: {len(test_actions)} options\")\n",
    "\n",
    "# Run the decision cycle\n",
    "start_time = time.time()\n",
    "chosen_action = agent.process_observation(test_observation, test_actions)\n",
    "total_time = time.time() - start_time\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"DECISION CYCLE COMPLETE\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nFinal Action Chosen: {chosen_action} - {test_actions[chosen_action]}\")\n",
    "print(f\"Total Time: {total_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and Analysis\n",
    "\n",
    "Display token usage summary and identify optimization opportunities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get token usage summary\n",
    "summary = agent.tracker.summary()\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"TOKEN USAGE SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nTotal Tokens: {summary['total_tokens']}\")\n",
    "print(f\"  Input: {summary['total_input_tokens']}\")\n",
    "print(f\"  Output: {summary['total_output_tokens']}\")\n",
    "print(f\"\\nTotal Time: {summary['total_duration_ms']}ms\")\n",
    "\n",
    "print(\"\\nBreakdown by Step:\")\n",
    "for step in summary['steps']:\n",
    "    print(f\"  {step['step']:<40} {step['tokens']:>6} tokens  {step['duration_ms']:>6}ms\")\n",
    "\n",
    "# Identify redundancies\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"OPTIMIZATION OPPORTUNITIES\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Check for redundancy between memory report and working memory update\n",
    "if 'memory_report' in agent.intermediate_results.get('3. Memory Report Generated', {}):\n",
    "    memory_report = agent.intermediate_results['3. Memory Report Generated']['memory_report']\n",
    "    working_memory_update = agent.intermediate_results.get('4. Working Memory Updated', {}).get('updated_working_memory', '')\n",
    "    \n",
    "    print(\"\\n1. Memory Report vs Working Memory Update:\")\n",
    "    print(f\"   Memory Report Length: {len(memory_report)} chars\")\n",
    "    print(f\"   Working Memory Length: {len(working_memory_update)} chars\")\n",
    "    print(f\"   Observation: These two steps are doing similar consolidation work\")\n",
    "\n",
    "# Check memory retrieval efficiency\n",
    "retrieved = agent.intermediate_results.get('2. Memories Retrieved', [])\n",
    "print(f\"\\n2. Memory Retrieval Efficiency:\")\n",
    "print(f\"   Queries Generated: {len(agent.intermediate_results.get('1. Memory Queries Generated', {}).get('queries', []))}\")\n",
    "print(f\"   Memories Retrieved: {len(retrieved)}\")\n",
    "print(f\"   Observation: Currently only using first memory per query\")\n",
    "\n",
    "# Check if long-term memory formation is always necessary\n",
    "ltm_formed = agent.intermediate_results.get('5. Long-term Memories Generated', {}).get('memories', [])\n",
    "print(f\"\\n3. Long-term Memory Formation:\")\n",
    "print(f\"   Memories Formed: {len(ltm_formed)}\")\n",
    "print(f\"   Observation: Every observation creates memories - should be selective\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "npc-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

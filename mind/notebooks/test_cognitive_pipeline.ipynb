{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NPC Cognitive Pipeline Testing\n",
    "\n",
    "This notebook provides full observability into the NPC cognitive pipeline using the new LangGraph architecture with proper Godot action schemas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "import asyncio\n",
    "from typing import Any\n",
    "from dataclasses import dataclass\n",
    "import logging\n",
    "\n",
    "# Import the new cognitive architecture\n",
    "from mind.cognitive_architecture.pipeline import CognitivePipeline\n",
    "from mind.cognitive_architecture.state import PipelineState\n",
    "from mind.cognitive_architecture.models import (\n",
    "    Observation,\n",
    "    StatusObservation,\n",
    "    NeedsObservation,\n",
    "    VisionObservation,\n",
    "    EntityData,\n",
    "    AvailableAction, \n",
    "    Action, \n",
    "    ActionType,\n",
    "    Memory\n",
    ")\n",
    "from mind.cognitive_architecture.nodes.cognitive_update.models import WorkingMemory\n",
    "from mind.cognitive_architecture.memory.vector_db_memory import VectorDBMemory\n",
    "\n",
    "# Import LangChain LLM wrapper\n",
    "from mind.apis.langchain_llm import get_llm, LangChainModel\n",
    "\n",
    "# Set up logging to see all intermediate steps\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Token Counter\n",
    "\n",
    "Simple token counting utility to measure usage at each step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "\n",
    "@dataclass\n",
    "class TokenUsage:\n",
    "    \"\"\"Track token usage for a single LLM call\"\"\"\n",
    "    step: str\n",
    "    input_tokens: int\n",
    "    output_tokens: int\n",
    "    total_tokens: int\n",
    "    duration_ms: int\n",
    "    \n",
    "class TokenTracker:\n",
    "    \"\"\"Track token usage across the pipeline\"\"\"\n",
    "    def __init__(self):\n",
    "        self.encoder = tiktoken.encoding_for_model(\"gpt-4\")  # Close enough for Claude\n",
    "        self.usage_history: list[TokenUsage] = []\n",
    "    \n",
    "    def count_tokens(self, text: str) -> int:\n",
    "        \"\"\"Count tokens in a string\"\"\"\n",
    "        return len(self.encoder.encode(text))\n",
    "    \n",
    "    def track_call(self, step: str, input_text: str, output_text: str, duration_ms: int):\n",
    "        \"\"\"Track a single LLM call\"\"\"\n",
    "        usage = TokenUsage(\n",
    "            step=step,\n",
    "            input_tokens=self.count_tokens(input_text),\n",
    "            output_tokens=self.count_tokens(output_text),\n",
    "            total_tokens=self.count_tokens(input_text) + self.count_tokens(output_text),\n",
    "            duration_ms=duration_ms\n",
    "        )\n",
    "        self.usage_history.append(usage)\n",
    "        return usage\n",
    "    \n",
    "    def summary(self) -> dict[str, Any]:\n",
    "        \"\"\"Get summary of all token usage\"\"\"\n",
    "        total_input = sum(u.input_tokens for u in self.usage_history)\n",
    "        total_output = sum(u.output_tokens for u in self.usage_history)\n",
    "        total_time = sum(u.duration_ms for u in self.usage_history)\n",
    "        \n",
    "        return {\n",
    "            \"total_input_tokens\": total_input,\n",
    "            \"total_output_tokens\": total_output,\n",
    "            \"total_tokens\": total_input + total_output,\n",
    "            \"total_duration_ms\": total_time,\n",
    "            \"steps\": [{\n",
    "                \"step\": u.step,\n",
    "                \"tokens\": u.total_tokens,\n",
    "                \"duration_ms\": u.duration_ms\n",
    "            } for u in self.usage_history]\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Pipeline Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize LLM via OpenRouter\n",
    "# Can easily switch models using LangChainModel constants\n",
    "llm = get_llm(LangChainModel.GEMINI_FLASH_LITE)\n",
    "\n",
    "# Initialize memory store\n",
    "memory_store = VectorDBMemory(collection_name=\"test_memories\")\n",
    "\n",
    "# Create the cognitive pipeline\n",
    "pipeline = CognitivePipeline(llm=llm, memory_store=memory_store)\n",
    "\n",
    "print(\"Pipeline initialized with nodes:\")\n",
    "print(\"  1. Memory Query\")\n",
    "print(\"  2. Memory Retrieval\") \n",
    "print(\"  3. Cognitive Update\")\n",
    "print(\"  4. Action Selection\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Scenario Setup\n",
    "\n",
    "Create a realistic test scenario using proper Godot action schemas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seed the memory store with initial memories\n",
    "# Note: Using default importance (1.0) for seeded memories since they're generic background knowledge\n",
    "initial_memories = [\n",
    "    \"Yesterday I shaped the blade and got it to the right length\",\n",
    "    \"The customer wants a ceremonial sword with intricate engravings\",\n",
    "    \"My apprentice has been learning quickly and can now help with basic tasks\",\n",
    "    \"The forge needs more coal soon, running low on supplies\",\n",
    "    \"Last week I completed a set of horseshoes for the stable\",\n",
    "    \"The village festival is coming up in three days\",\n",
    "    \"I promised my wife I would come home early today\",\n",
    "    \"The apprentice's name is Tom and he's been working with me for 3 months\",\n",
    "    \"I have a bad back from years of smithing work\",\n",
    "    \"The local inn keeper is my best customer\"\n",
    "]\n",
    "\n",
    "# Clear and repopulate memory store\n",
    "memory_store.clear()\n",
    "for memory_content in initial_memories:\n",
    "    memory = memory_store.add_memory(memory_content)  # Uses default importance\n",
    "    print(f\"Added memory: {memory_content[:50]}...\")\n",
    "\n",
    "print(f\"\\nTotal memories in store: {memory_store.collection.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create test observation with structured models\n",
    "observation = Observation(\n",
    "    entity_id=\"blacksmith_001\",\n",
    "    current_simulation_time=100,  # Game time\n",
    "    status=StatusObservation(\n",
    "        position=(5, 10),\n",
    "        movement_locked=False\n",
    "    ),\n",
    "    needs=NeedsObservation(\n",
    "        needs={\n",
    "            \"hunger\": 75.0,\n",
    "            \"energy\": 60.0,\n",
    "            \"fun\": 40.0,\n",
    "            \"hygiene\": 80.0\n",
    "        }\n",
    "    ),\n",
    "    vision=VisionObservation(\n",
    "        visible_entities=[\n",
    "            EntityData(\n",
    "                entity_id=\"tom_001\",\n",
    "                display_name=\"Tom\",\n",
    "                position=(6, 10),\n",
    "                interactions={\n",
    "                    \"conversation\": {\n",
    "                        \"name\": \"conversation\",\n",
    "                        \"description\": \"Talk with Tom\",\n",
    "                        \"needs_filled\": [\"fun\"],\n",
    "                        \"needs_drained\": [\"energy\"]\n",
    "                    }\n",
    "                }\n",
    "            ),\n",
    "            EntityData(\n",
    "                entity_id=\"sword_blade_001\",\n",
    "                display_name=\"Sword Blade\",\n",
    "                position=(5, 11),\n",
    "                interactions={\n",
    "                    \"craft\": {\n",
    "                        \"name\": \"craft\",\n",
    "                        \"description\": \"Continue working on the sword blade\",\n",
    "                        \"needs_filled\": [\"fun\"],\n",
    "                        \"needs_drained\": [\"energy\"]\n",
    "                    }\n",
    "                }\n",
    "            ),\n",
    "            EntityData(\n",
    "                entity_id=\"forge_001\",\n",
    "                display_name=\"Forge\",\n",
    "                position=(4, 10),\n",
    "                interactions={\n",
    "                    \"restart_fire\": {\n",
    "                        \"name\": \"restart_fire\",\n",
    "                        \"description\": \"Restart the forge fire\",\n",
    "                        \"needs_filled\": [],\n",
    "                        \"needs_drained\": [\"energy\"]\n",
    "                    }\n",
    "                }\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "\n",
    "# Available actions\n",
    "available_actions = [\n",
    "    AvailableAction(\n",
    "        name=\"MOVE_TO\",\n",
    "        description=\"Move to a specific cell\",\n",
    "        parameters={\"destination\": \"Target position to move to\"}\n",
    "    ),\n",
    "    AvailableAction(\n",
    "        name=\"INTERACT_WITH\",\n",
    "        description=\"Interact with an item or NPC\",\n",
    "        parameters={\n",
    "            \"entity_id\": \"Target entity ID\",\n",
    "            \"interaction_name\": \"Name of interaction to request\"\n",
    "        }\n",
    "    ),\n",
    "    AvailableAction(\n",
    "        name=\"WANDER\",\n",
    "        description=\"Move to a random location\",\n",
    "        parameters={\"range\": \"Maximum wander distance from current position\"}\n",
    "    ),\n",
    "    AvailableAction(\n",
    "        name=\"WAIT\",\n",
    "        description=\"Wait for a specified duration\",\n",
    "        parameters={\"duration\": \"How long to wait in seconds\"}\n",
    "    ),\n",
    "    AvailableAction(\n",
    "        name=\"CONTINUE\",\n",
    "        description=\"Continue current activity\",\n",
    "        parameters={}\n",
    "    )\n",
    "]\n",
    "\n",
    "# Personality traits\n",
    "personality_traits = [\"hardworking\", \"perfectionist\", \"patient teacher\", \"caring mentor\"]\n",
    "\n",
    "# Initial working memory\n",
    "initial_working_memory = WorkingMemory(\n",
    "    situation_assessment=\"I am a blacksmith in the village. I've been working on a sword commission for the past two days.\",\n",
    "    active_goals=[\"Finish the sword blade today\", \"Start on the handle tomorrow\"],\n",
    "    emotional_state=\"Well-rested despite back pain\"\n",
    ")\n",
    "\n",
    "print(\"Test scenario created:\")\n",
    "print(f\"  Entity: {observation.entity_id}\")\n",
    "print(f\"  Position: {observation.status.position if observation.status else 'Unknown'}\")\n",
    "print(f\"  Visible entities: {len(observation.vision.visible_entities) if observation.vision else 0}\")\n",
    "print(f\"  Available actions: {len(available_actions)}\")\n",
    "print(f\"  Personality traits: {', '.join(personality_traits)}\")\n",
    "print(f\"\\nObservation (formatted for LLM):\")\n",
    "print(str(observation))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display Available Actions\n",
    "\n",
    "Show how the actions format themselves for the LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Available Actions (as formatted for LLM):\")\n",
    "print(\"=\"*60)\n",
    "for i, action in enumerate(available_actions, 1):\n",
    "    print(f\"{i}. {str(action)}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Cognitive Pipeline\n",
    "\n",
    "Execute the pipeline with full observability of each step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def run_pipeline_with_observation(pipeline, observation, available_actions, personality_traits, working_memory):\n",
    "    \"\"\"Run the pipeline and display results\"\"\"\n",
    "    \n",
    "    state = PipelineState(\n",
    "        observation=observation,\n",
    "        available_actions=available_actions,\n",
    "        personality_traits=personality_traits,\n",
    "        working_memory=working_memory\n",
    "    )\n",
    "    \n",
    "    print(\"=\"*70)\n",
    "    print(\"COGNITIVE PIPELINE EXECUTION\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Run the pipeline\n",
    "    start_time = time.time()\n",
    "    result = await pipeline.process(state)\n",
    "    total_time = time.time() - start_time\n",
    "    \n",
    "    # Display step results\n",
    "    print(f\"\\n1. MEMORY QUERIES ({result.time_ms.get('memory_query', 0)}ms):\")\n",
    "    for query in result.memory_queries:\n",
    "        print(f\"   • {query}\")\n",
    "    \n",
    "    print(f\"\\n2. MEMORIES RETRIEVED ({result.time_ms.get('memory_retrieval', 0)}ms):\")\n",
    "    for memory in result.retrieved_memories:\n",
    "        print(f\"   {str(memory)}\")\n",
    "    \n",
    "    print(f\"\\n3. COGNITIVE UPDATE ({result.time_ms.get('cognitive_update', 0)}ms):\")\n",
    "    print(json.dumps(result.cognitive_context, indent=2))\n",
    "    \n",
    "    print(f\"\\n   Working Memory:\")\n",
    "    print(f\"   {str(result.working_memory)}\")\n",
    "    \n",
    "    print(f\"\\n4. ACTION SELECTED ({result.time_ms.get('action_selection', 0)}ms):\")\n",
    "    if result.chosen_action:\n",
    "        print(f\"   {str(result.chosen_action)}\")\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"Total: {total_time:.2f}s | {sum(result.tokens_used.values())} tokens\")\n",
    "    print(f\"{'='*70}\\n\")\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Run the pipeline\n",
    "result = await run_pipeline_with_observation(\n",
    "    pipeline,\n",
    "    observation,\n",
    "    available_actions,\n",
    "    personality_traits,\n",
    "    initial_working_memory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Daily Memories Formed:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "if result.daily_memories:\n",
    "    for mem in result.daily_memories:\n",
    "        print(f\"[{mem.importance:.1f}/10] {mem.content}\")\n",
    "else:\n",
    "    print(\"No significant memories formed (routine action)\")\n",
    "\n",
    "# Demonstrate consolidation if needed\n",
    "if result.daily_memories:\n",
    "    from mind.cognitive_architecture.nodes.memory_consolidation import MemoryConsolidationNode\n",
    "    \n",
    "    print(\"\\nConsolidating to long-term storage...\")\n",
    "    consolidation_node = MemoryConsolidationNode(memory_store)\n",
    "    await consolidation_node.process(result)\n",
    "    print(f\"✓ Added {len(result.daily_memories)} memories\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Memory Formation Analysis\n",
    "\n",
    "Examine what memories were formed during the decision cycle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Format Action for MCP Protocol\n",
    "\n",
    "Show how the selected action would be sent back to Godot via MCP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if result.chosen_action:\n",
    "    # Format as MCP response\n",
    "    mcp_response = {\n",
    "        \"action\": result.chosen_action.action,\n",
    "        \"parameters\": result.chosen_action.parameters\n",
    "    }\n",
    "    \n",
    "    print(\"MCP Response to Godot:\")\n",
    "    print(\"=\"*40)\n",
    "    print(json.dumps(mcp_response, indent=2))\n",
    "    \n",
    "    print(\"\\nThis action would cause the NPC to:\")\n",
    "    if result.chosen_action.action == \"interact_with\":\n",
    "        entity = result.chosen_action.parameters.get(\"entity_id\", \"unknown\")\n",
    "        interaction = result.chosen_action.parameters.get(\"interaction_name\", \"unknown\")\n",
    "        print(f\"  → Request a '{interaction}' interaction with entity '{entity}'\")\n",
    "        print(f\"  → Transition to NpcBiddingState in the controller\")\n",
    "    elif result.chosen_action.action == \"move_to\":\n",
    "        dest = result.chosen_action.parameters.get(\"destination\", \"unknown\")\n",
    "        print(f\"  → Navigate to grid position {dest}\")\n",
    "        print(f\"  → Transition to MovingState in the controller\")\n",
    "    elif result.chosen_action.action == \"wait\":\n",
    "        duration = result.chosen_action.parameters.get(\"duration\", 1.0)\n",
    "        print(f\"  → Pause for {duration} seconds\")\n",
    "        print(f\"  → Transition to WaitingState in the controller\")\n",
    "    elif result.chosen_action.action == \"wander\":\n",
    "        print(f\"  → Randomly explore the environment\")\n",
    "        print(f\"  → Transition to WanderingState in the controller\")\n",
    "    elif result.chosen_action.action == \"continue\":\n",
    "        print(f\"  → Continue current behavior unchanged\")\n",
    "        print(f\"  → No state transition\")\n",
    "else:\n",
    "    print(\"No action was selected by the pipeline\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Different Scenarios\n",
    "\n",
    "Try the pipeline with different observations to see how it responds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Urgent scenario - low on supplies\n",
    "urgent_observation = Observation(\n",
    "    entity_id=\"blacksmith_001\",\n",
    "    current_simulation_time=150,\n",
    "    status=StatusObservation(\n",
    "        position=(5, 10),\n",
    "        movement_locked=False\n",
    "    ),\n",
    "    needs=NeedsObservation(\n",
    "        needs={\n",
    "            \"hunger\": 70.0,\n",
    "            \"energy\": 55.0,\n",
    "            \"fun\": 30.0,\n",
    "            \"hygiene\": 75.0\n",
    "        }\n",
    "    ),\n",
    "    vision=VisionObservation(\n",
    "        visible_entities=[\n",
    "            EntityData(\n",
    "                entity_id=\"tom_001\",\n",
    "                display_name=\"Tom\",\n",
    "                position=(6, 10),\n",
    "                interactions={\n",
    "                    \"conversation\": {\n",
    "                        \"name\": \"conversation\",\n",
    "                        \"description\": \"Talk with Tom about getting more coal urgently\",\n",
    "                        \"needs_filled\": [\"fun\"],\n",
    "                        \"needs_drained\": [\"energy\"]\n",
    "                    }\n",
    "                }\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "\n",
    "urgent_available_actions = [\n",
    "    AvailableAction(\n",
    "        name=\"INTERACT_WITH\",\n",
    "        description=\"Interact with an item or NPC\",\n",
    "        parameters={\n",
    "            \"entity_id\": \"Target entity ID\",\n",
    "            \"interaction_name\": \"Name of interaction to request\"\n",
    "        }\n",
    "    ),\n",
    "    AvailableAction(\n",
    "        name=\"MOVE_TO\",\n",
    "        description=\"Move to a specific cell\",\n",
    "        parameters={\"destination\": \"Target position to move to\"}\n",
    "    ),\n",
    "    AvailableAction(\n",
    "        name=\"WAIT\",\n",
    "        description=\"Wait for a specified duration\",\n",
    "        parameters={\"duration\": \"How long to wait in seconds\"}\n",
    "    ),\n",
    "    AvailableAction(\n",
    "        name=\"CONTINUE\",\n",
    "        description=\"Continue current activity\",\n",
    "        parameters={}\n",
    "    )\n",
    "]\n",
    "\n",
    "urgent_traits = [\"hardworking\", \"perfectionist\", \"patient teacher\", \"resourceful\"]\n",
    "\n",
    "print(\"Testing URGENT scenario:\")\n",
    "print(\"=\"*40)\n",
    "print(\"\\nObservation context:\")\n",
    "print(str(urgent_observation))\n",
    "\n",
    "urgent_result = await pipeline.process(PipelineState(\n",
    "    observation=urgent_observation,\n",
    "    available_actions=urgent_available_actions,\n",
    "    personality_traits=urgent_traits,\n",
    "    working_memory=result.working_memory\n",
    "))\n",
    "\n",
    "print(f\"\\nAction: {str(urgent_result.chosen_action)}\")\n",
    "print(f\"\\nCognitive Context:\")\n",
    "print(json.dumps(urgent_result.cognitive_context, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Memory Analysis\n",
    "\n",
    "Examine what memories were retrieved and why."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Memory Retrieval Analysis\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Import the query model\n",
    "from mind.cognitive_architecture.memory.vector_db_memory import VectorDBQuery\n",
    "\n",
    "# Test memory retrieval with different queries\n",
    "test_queries = [\n",
    "    \"apprentice Tom teaching\",\n",
    "    \"sword blade commission\",\n",
    "    \"coal forge supplies\",\n",
    "    \"wife promise home\"\n",
    "]\n",
    "\n",
    "for query_text in test_queries:\n",
    "    query = VectorDBQuery(query=query_text, top_k=2)\n",
    "    memories = await memory_store.search(query)\n",
    "    print(f\"\\nQuery: '{query_text}'\")\n",
    "    print(\"-\"*40)\n",
    "    for i, memory in enumerate(memories, 1):\n",
    "        print(f\"  {i}. {memory.content}\")\n",
    "        print(f\"     Importance: {memory.importance:.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Summary\n",
    "\n",
    "Analyze the performance characteristics of the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect timing and token data from multiple runs\n",
    "timing_results = []\n",
    "\n",
    "print(\"Running pipeline 3 times to measure performance...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for i in range(3):\n",
    "    test_state = PipelineState(\n",
    "        observation=observation,\n",
    "        available_actions=available_actions,\n",
    "        personality_traits=personality_traits,\n",
    "        working_memory=initial_working_memory\n",
    "    )\n",
    "    \n",
    "    start = time.time()\n",
    "    test_result = await pipeline.process(test_state)\n",
    "    elapsed = (time.time() - start) * 1000  # Convert to ms\n",
    "    \n",
    "    timing_results.append({\n",
    "        \"run\": i + 1,\n",
    "        \"total_ms\": elapsed,\n",
    "        \"memory_query_ms\": test_result.time_ms.get('memory_query', 0),\n",
    "        \"memory_retrieval_ms\": test_result.time_ms.get('memory_retrieval', 0),\n",
    "        \"cognitive_update_ms\": test_result.time_ms.get('cognitive_update', 0),\n",
    "        \"action_selection_ms\": test_result.time_ms.get('action_selection', 0),\n",
    "        \"memory_query_tokens\": test_result.tokens_used.get('memory_query', 0),\n",
    "        \"cognitive_update_tokens\": test_result.tokens_used.get('cognitive_update', 0),\n",
    "        \"action_selection_tokens\": test_result.tokens_used.get('action_selection', 0),\n",
    "    })\n",
    "    print(f\"Run {i+1}: {elapsed:.0f}ms total, {sum(test_result.tokens_used.values())} tokens\")\n",
    "\n",
    "print(\"\\nPerformance Summary:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Calculate averages\n",
    "avg_total = sum(r['total_ms'] for r in timing_results) / len(timing_results)\n",
    "avg_query = sum(r['memory_query_ms'] for r in timing_results) / len(timing_results)\n",
    "avg_retrieval = sum(r['memory_retrieval_ms'] for r in timing_results) / len(timing_results)\n",
    "avg_cognitive = sum(r['cognitive_update_ms'] for r in timing_results) / len(timing_results)\n",
    "avg_action = sum(r['action_selection_ms'] for r in timing_results) / len(timing_results)\n",
    "\n",
    "avg_query_tokens = sum(r['memory_query_tokens'] for r in timing_results) / len(timing_results)\n",
    "avg_cognitive_tokens = sum(r['cognitive_update_tokens'] for r in timing_results) / len(timing_results)\n",
    "avg_action_tokens = sum(r['action_selection_tokens'] for r in timing_results) / len(timing_results)\n",
    "avg_total_tokens = avg_query_tokens + avg_cognitive_tokens + avg_action_tokens\n",
    "\n",
    "print(f\"Average Total Time: {avg_total:.0f}ms\")\n",
    "print(f\"\\nBreakdown by Step:\")\n",
    "print(f\"  Memory Query:     {avg_query:.0f}ms ({avg_query/avg_total*100:.1f}%) | {avg_query_tokens:.0f} tokens\")\n",
    "print(f\"  Memory Retrieval: {avg_retrieval:.0f}ms ({avg_retrieval/avg_total*100:.1f}%) | 0 tokens (vector search)\")\n",
    "print(f\"  Cognitive Update: {avg_cognitive:.0f}ms ({avg_cognitive/avg_total*100:.1f}%) | {avg_cognitive_tokens:.0f} tokens\")\n",
    "print(f\"  Action Selection: {avg_action:.0f}ms ({avg_action/avg_total*100:.1f}%) | {avg_action_tokens:.0f} tokens\")\n",
    "\n",
    "print(f\"\\nToken Usage:\")\n",
    "print(f\"  Total: {avg_total_tokens:.0f} tokens per decision\")\n",
    "print(f\"  Cost estimate (Gemini Flash Lite): ${avg_total_tokens * 0.000000075:.6f} per decision\")\n",
    "print(f\"  Cost estimate (Claude Sonnet 4): ${avg_total_tokens * 0.000003:.6f} per decision\")\n",
    "\n",
    "print(f\"\\nObservations:\")\n",
    "llm_time = avg_query + avg_cognitive + avg_action\n",
    "print(f\"  - LLM calls account for {llm_time/avg_total*100:.1f}% of total time\")\n",
    "print(f\"  - Memory retrieval (vector search) is {avg_retrieval/avg_total*100:.1f}% of total time\")\n",
    "if avg_cognitive > avg_action:\n",
    "    print(f\"  - Cognitive update is the slowest LLM step\")\n",
    "else:\n",
    "    print(f\"  - Action selection is the slowest LLM step\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mind-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy prompt optimization code over\n",
    "\n",
    "# optimization:\n",
    "# - Have a list of scenarios. Each scenario consists of a state, an acting agent, and an intent. It should also include an example output (including modifications to the state).\n",
    "# - Have a list of seed prompts.\n",
    "# - Initialize a list of prompt objects. Each prompt object should have the following properties:\n",
    "#   - A prompt string.\n",
    "#   - Past (scenario, output, judgment) tuples. Each judgment object should have a rating along with the judge's reasoning.\n",
    "# - For each optimization iteration:\n",
    "#   - Sample a prompt object. Likelihood of sampling should be based on the the mean and variance of its ratings, as well as the number of past judgments.\n",
    "#   - Transform the prompt through mutation, crossover, or the identity function. If the transformation is nont the identity, then put it into a new prompt object.\n",
    "#     - Mutation: Sample a reasoning strategy to help guide the judge in tweaking the prompt.\n",
    "#     - Crossover: Sample another prompt object and have the judge combine them.\n",
    "#   - Sample a scenario (likelihood inversely proportional to the number of times it has been sampled for this prompt).\n",
    "#   - Generate output and evaluate the output.\n",
    "\n",
    "# evaluation:\n",
    "# - Have a rubric for evaluating the output.\n",
    "# - Have a list of rules. Breaking a rule is a penalty.\n",
    "# - Have an example output for each scenario. This should guide the judge, although it is ok to deviate from it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization:\n",
    "- Have a list of scenarios. Each scenario consists of a state, an acting agent, and an intent. It should also include an example output (including modifications to the state).\n",
    "- Have a list of seed prompts.\n",
    "- Initialize a list of prompt objects. Each prompt object should have the following properties:\n",
    "  - A prompt string.\n",
    "  - Past (scenario, output, judgment) tuples. Each judgment object should have a rating along with the judge's reasoning.\n",
    "- For each optimization iteration:\n",
    "  - Sample a prompt object. Likelihood of sampling should be based on the the mean and variance of its ratings, as well as the number of past judgments.\n",
    "  - Transform the prompt through mutation, crossover, or the identity function. If the transformation is nont the identity, then put it into a new prompt object.\n",
    "    - Mutation: Sample a reasoning strategy to help guide the judge in tweaking the prompt.\n",
    "    - Crossover: Sample another prompt object and have the judge combine them.\n",
    "  - Sample a scenario (likelihood inversely proportional to the number of times it has been sampled for this prompt).\n",
    "  - Generate output and evaluate the output.\n",
    "\n",
    "### Evaluation:\n",
    "- Have a rubric for evaluating the output.\n",
    "- Have a list of rules. Breaking a rule is a penalty.\n",
    "- Have an example output for each scenario. This should guide the judge, although it is ok to deviate from it.\n",
    "\n",
    "### Implementation:\n",
    "- Copy prompt optimization code over to implement a simplified mutation-only version\n",
    "  - Write the evaluation rubric\n",
    "  - Create the scenarios\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unit Test Idea\n",
    "- Could have a set of simple deterministic unit tests which should be passed. This could avoid needing a large LLM for judgment. For e.g.:\n",
    "  - Define which properties should be changed. Use a small local LLM to check if the values are as expected\n",
    "    - When agent picks up an item, it should go to their inventory. It should also have its location updated. Nothing else should change.\n",
    "    - When agent knocks down a dominoe, the whole line of them should fall\n",
    "    - When an agent has the requisite tools/skills, they should succeed. Otherwise, they should have a low chance of succeeding\n",
    "- Small LLM usage\n",
    "  - Ask a series of questions (depending on the test case) which probe how good the response is\n",
    "    - For nondeterministic test cases:\n",
    "        - Does agent rigorously quantify uncertainty?\n",
    "        - Do potential outcomes roughly match the expected outcomes?\n",
    "    - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import config\n",
    "from openai import OpenAI\n",
    "\n",
    "openai_client = None\n",
    "\n",
    "GPT_35 = 'gpt-3.5-turbo-1106'\n",
    "GPT_4 = 'gpt-4-1106-preview'\n",
    "\n",
    "def authenticate_openai(api_key):\n",
    "    global openai_client\n",
    "    openai_client = OpenAI(api_key=api_key)\n",
    "\n",
    "def get_llm_completion(prompt, system_prompt, model=GPT_35):\n",
    "    completion = openai_client.chat.completions.create(model=model,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ])\n",
    "    return completion.choices[0].message.content\n",
    "\n",
    "api_keys_path = \"../../api_keys.cfg\"\n",
    "api_keys = config.Config(api_keys_path)\n",
    "authenticate_openai(api_keys['OPENAI_API_KEY'])\n",
    "\n",
    "get_llm_completion(\"What is 1+1?\", \"Answer all questions as briefly as possible.\", GPT_35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class Scenario:\n",
    "    state: dict\n",
    "    acting_agent: str\n",
    "    intent: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write down the prompt (broken down into parts)\n",
    "# for each part, write down a rubric / evaluation function\n",
    "\n",
    "state = {\n",
    "  \"agents\": {\n",
    "    \"Alice\": {\n",
    "      \"location\": \"standing by table1\",\n",
    "      \"inventory\": {\n",
    "        \"circuit_board\": {\n",
    "          \"description\": \"a small electronic circuit board\"\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  },\n",
    "  \"entities\": {\n",
    "    \"dominoe1\": {\n",
    "      \"description\": \"a dominoe with 3 pips on it\",\n",
    "      \"location\": \"center of the room\",\n",
    "    },\n",
    "    \"dominoe2\": {\n",
    "      \"description\": \"a dominoe with 5 pips on it\",\n",
    "      \"location\": \"center of the room, in front of dominoe1\",\n",
    "    },\n",
    "    \"dominoe3\": {\n",
    "      \"description\": \"a dominoe with 1 pip on it\",\n",
    "      \"location\": \"center of the room, in front of dominoe2\",\n",
    "    },\n",
    "  },\n",
    "}\n",
    "acting_agent = \"Alice\"\n",
    "intent = \"Push over dominoe1\"\n",
    "expected_outcome = \"dominow1 should be pushed over, and start a chain reastion which results in all dominos being pushed over\"\n",
    "\n",
    "scenario = Scenario(state, acting_agent, intent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# elicit answer from gpt-3.5-turbo-1106\n",
    "\n",
    "# have gpt4 evaluate the answer using the rules and expected outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "reasoning_plan = [\n",
    "    {\n",
    "      \"step\": 1,\n",
    "      \"description\": \"Relevant actors / entities\",\n",
    "      \"action\": \"Identify actors and entities that are pertinent to the intent's context and outcome. Explain their relevance.\"\n",
    "    },\n",
    "    {\n",
    "      \"step\": 2,\n",
    "      \"description\": \"Relevant properties of selected actors / entities\",\n",
    "      \"action\": \"Determine which properties of the identified actors and entities could influence the outcome and explain the reasons.\"\n",
    "    },\n",
    "    {\n",
    "      \"step\": 3,\n",
    "      \"description\": \"Relevant relations between selected actors / entities\",\n",
    "      \"action\": \"Examine the interactions and relationships between the actors and entities that could impact the outcome. Provide explanations for each identified relationship.\"\n",
    "    },\n",
    "    {\n",
    "      \"step\": 4,\n",
    "      \"description\": \"Relevant facts\",\n",
    "      \"action\": \"Summarize the essential information extracted from the previous steps into a concise bullet point list that abstracts the situation at a higher level.\"\n",
    "    },\n",
    "    {\n",
    "      \"step\": 5,\n",
    "      \"description\": \"Outcome exploration\",\n",
    "      \"action\": \"Introduce structured variability by selecting variables that can change based on chance or state conditions.\"\n",
    "    },\n",
    "    {\n",
    "      \"step\": 6,\n",
    "      \"description\": \"Outcome analysis\",\n",
    "      \"action\": \"Analyze the relevant facts to establish the probability distributions for each variable.\"\n",
    "    },\n",
    "    {\n",
    "      \"step\": 7,\n",
    "      \"description\": \"Outcome choice\",\n",
    "      \"action\": \"Generate code to determine the outcomes of the variables, and present the results in a format understandable to humans.\"\n",
    "    },\n",
    "    {\n",
    "      \"step\": 8,\n",
    "      \"description\": \"Outcome decomposition\",\n",
    "      \"action\": \"Create a detailed sequence of events that unfold as a result of the intent, specifying the title and effects for each event.\"\n",
    "    },\n",
    "    {\n",
    "      \"step\": 9,\n",
    "      \"description\": \"Outcome implementation\",\n",
    "      \"action\": \"Write code to update the simulation state based on the sequence of events.\"\n",
    "    }\n",
    "]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
